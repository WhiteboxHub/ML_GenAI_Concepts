{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.26.1)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface_hub) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface_hub) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/innovapathinc/Library/Python/3.10/lib/python/site-packages (from huggingface_hub) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface_hub) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/innovapathinc/Library/Python/3.10/lib/python/site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->huggingface_hub) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->huggingface_hub) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->huggingface_hub) (2024.8.30)\n",
      "Requirement already satisfied: sentence-transformers in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (2.2.2)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-3.2.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sentence-transformers) (4.45.2)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sentence-transformers) (4.66.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sentence-transformers) (2.0.1)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sentence-transformers) (1.14.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sentence-transformers) (0.26.1)\n",
      "Requirement already satisfied: Pillow in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sentence-transformers) (11.0.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/innovapathinc/Library/Python/3.10/lib/python/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/innovapathinc/Library/Python/3.10/lib/python/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Using cached sentence_transformers-3.2.1-py3-none-any.whl (255 kB)\n",
      "Installing collected packages: sentence-transformers\n",
      "  Attempting uninstall: sentence-transformers\n",
      "    Found existing installation: sentence-transformers 2.2.2\n",
      "    Uninstalling sentence-transformers-2.2.2:\n",
      "      Successfully uninstalled sentence-transformers-2.2.2\n",
      "Successfully installed sentence-transformers-3.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --upgrade huggingface_hub\n",
    "!pip3 install --upgrade sentence-transformers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for macos installation of libraries \n",
    "!pip3 install requests numpy faiss-cpu scikit-learn rouge-score nltk\n",
    "\n",
    "#for windows\n",
    "%pip install requests numpy faiss-cpu scikit-learn rouge-score nltk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import faiss\n",
    "from pdfminer.high_level import extract_text\n",
    "from sentence_transformers import SentenceTransformer\n",
    "# from huggingface_hub import hf_hub_download\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained embedding model\n",
    "# This line initializes the SentenceTransformer model 'all-MiniLM-L6-v2', a compact, \n",
    "# efficient model for creating sentence embeddings that capture semantic meaning.\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding and Text Extraction Utilities\n",
    "\n",
    "This script provides utilities for generating text embeddings, extracting text from PDF files, and loading metadata from JSONL files. It leverages the `SentenceTransformer` model to create embeddings that represent the input text, making it suitable for similarity search tasks. Additionally, it uses `extract_text` for reading content from PDFs and handles any file-related errors gracefully. The `load_metadata` function reads JSONL metadata for further document processing.\n",
    "\n",
    "## Code Overview\n",
    "\n",
    "1. **generate_embeddings(text)**: Creates embeddings for input text using a pre-trained `SentenceTransformer` model.\n",
    "2. **extract_pdf_text(pdf_path)**: Extracts text from the specified PDF file; handles errors if extraction fails.\n",
    "3. **load_metadata(jsonl_file)**: Reads metadata from a JSONL file and loads it as a list of JSON objects for use in downstream tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(text):\n",
    "    \"\"\"Generate embeddings for the given text.\"\"\"\n",
    "    \n",
    "    return model.encode(text, convert_to_tensor=True)\n",
    "\n",
    "def extract_pdf_text(pdf_path):\n",
    "    \"\"\"Extract text from a PDF file.\"\"\"\n",
    "    try:\n",
    "        return extract_text(pdf_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from {pdf_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def load_metadata(jsonl_file):\n",
    "    \"\"\"Load metadata from a JSONL file.\"\"\"\n",
    "    try:\n",
    "        with open(jsonl_file, 'r') as f:\n",
    "            return [json.loads(line) for line in f]\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading metadata from {jsonl_file}: {e}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded metadata: [{'doc_name': '3M_2015_10K', 'company': '3M', 'gics_sector': 'Industrials', 'doc_type': '10k', 'doc_period': 2015, 'doc_link': 'https://investors.3m.com/financials/sec-filings/content/0001558370-16-003162/0001558370-16-003162.pdf'}, {'doc_name': '3M_2016_10K', 'company': '3M', 'gics_sector': 'Industrials', 'doc_type': '10k', 'doc_period': 2016, 'doc_link': 'https://investors.3m.com/financials/sec-filings/content/0001558370-17-000479/0001558370-17-000479.pdf'}, {'doc_name': '3M_2017_10K', 'company': '3M', 'gics_sector': 'Industrials', 'doc_type': '10k', 'doc_period': 2017, 'doc_link': 'https://investors.3m.com/financials/sec-filings/content/0001558370-18-000535/0001558370-18-000535.pdf'}, {'doc_name': '3M_2018_10K', 'company': '3M', 'gics_sector': 'Industrials', 'doc_type': '10k', 'doc_period': 2018, 'doc_link': 'https://investors.3m.com/financials/sec-filings/content/0001558370-19-000470/0001558370-19-000470.pdf'}, {'doc_name': '3M_2022_10K', 'company': '3M', 'gics_sector': 'Industrials', 'doc_type': '10k', 'doc_period': 2022, 'doc_link': 'https://investors.3m.com/financials/sec-filings/content/0000066740-23-000014/0000066740-23-000014.pdf'}]\n"
     ]
    }
   ],
   "source": [
    "# Define your paths\n",
    "jsonl_file = \"/Users/innovapathinc/Desktop/Response_eval/data/financebench_document_information.jsonl\"\n",
    "pdf_files = [\n",
    "    \"/Users/innovapathinc/Desktop/Response_eval/data/3M_2015_10K.pdf\",\n",
    "    \"/Users/innovapathinc/Desktop/Response_eval/data/3M_2016_10K.pdf\"\n",
    "]\n",
    "\n",
    "# Load metadata from JSONL file\n",
    "metadata = load_metadata(jsonl_file)\n",
    "print(\"Loaded metadata:\", metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored embedding for 3M_2015_10K.pdf in the index.\n",
      "Stored embedding for 3M_2016_10K.pdf in the index.\n"
     ]
    }
   ],
   "source": [
    "# Initialize FAISS index\n",
    "index = faiss.IndexFlatL2(384)  # Dimension should match your embedding size\n",
    "\n",
    "# Extract text from all PDF files and store embeddings\n",
    "for pdf_file in pdf_files:\n",
    "    pdf_name = os.path.basename(pdf_file)\n",
    "    pdf_text = extract_pdf_text(pdf_file)\n",
    "    embedding = generate_embeddings(pdf_text).cpu().numpy()  # Convert to numpy array\n",
    "    index.add(np.array([embedding]))  # Add to FAISS index\n",
    "    print(f\"Stored embedding for {pdf_name} in the index.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to retrieve the top K most similar documents for a given query\n",
    "def retrieve_documents(query, index, k=3):\n",
    "    query_embedding = generate_embeddings(query).cpu().numpy()\n",
    "    distances, indices = index.search(np.array([query_embedding]), k)\n",
    "    return indices[0], distances[0]  # Return indices and distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "query = \"What are the key financials of 3M in 2020?\"\n",
    "top_docs, top_distances = retrieve_documents(query, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top retrieved documents indices: [ 0  1 -1]\n",
      "Distances: [1.4042511e+00 1.4111483e+00 3.4028235e+38]\n",
      "Document: 3M_2015_10K.pdf\n",
      "Document: 3M_2016_10K.pdf\n",
      "Document: 3M_2022_10K.pdf\n"
     ]
    }
   ],
   "source": [
    "# Display the top retrieved document indices and distances\n",
    "print(f\"Top retrieved documents indices: {top_docs}\")\n",
    "print(f\"Distances: {top_distances}\")\n",
    "\n",
    "# Print the names of the top retrieved documents using the metadata\n",
    "for doc_index in top_docs:\n",
    "    if doc_index < len(metadata):  # Ensure index is within bounds\n",
    "        doc_name = metadata[doc_index]['doc_name']\n",
    "        print(f\"Document: {doc_name}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from Mistral AI:\n",
      "To find the executive officers of 3M Company in 2015, you would need to refer to the 3M_2015_10K document. Here is a general guide on how to locate this information:\n",
      "\n",
      "1. **Open the 3M_2015_10K document** linked in the provided content.\n",
      "2. **Navigate to the section on executive officers**. This section is typically found in the beginning of the document, often in the \"Item 1\" or \"Item 4\" section, which details information about the company's board of directors and executive officers.\n",
      "3. **Look for a heading such as \"Executive Officers\" or \"Management\"**.\n",
      "\n",
      "The specific names and positions of the executive officers should be listed there. Here is a general format you might expect:\n",
      "\n",
      "- **Chief Executive Officer (CEO)**\n",
      "- **Chief Financial Officer (CFO)**\n",
      "- **Chief Operating Officer (COO)**\n",
      "- **Other executive positions (e.g., Chief Legal Officer, Chief Technical Officer, etc.)**\n",
      "\n",
      "For a precise list, you would need to consult the document directly.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "# Set your Mistral API URL and API key\n",
    "mistral_api_url = \"https://api.mistral.ai/v1/chat/completions\"\n",
    "# Update with the actual endpoint\n",
    "mistral_api_key = \"KoxLAEgGVZeEMPv3AJ3KSA4aJV6ZxPmo\"\n",
    "\n",
    "def generate_response(context, query):\n",
    "    \"\"\"Generate a response using Mistral AI.\"\"\"\n",
    "    prompt = f\"Based on the following content: {context}\\nAnswer the query: {query}\"\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {mistral_api_key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"mistral-small-latest\",  # Replace with the actual model name\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"max_tokens\": 300\n",
    "    }\n",
    "\n",
    "    response = requests.post(mistral_api_url, headers=headers, json=payload)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json()['choices'][0]['message']['content'].strip()\n",
    "    else:\n",
    "        raise Exception(f\"Error {response.status_code}: {response.text}\")\n",
    "\n",
    "def retrieve_documents(query, index, metadata, k=3):\n",
    "    \"\"\"Retrieve the top K most similar documents for a given query.\"\"\"\n",
    "    query_embedding = generate_embeddings(query).cpu().numpy()  # Ensure the embedding is on CPU\n",
    "    distances, indices = index.search(np.array([query_embedding]), k)\n",
    "\n",
    "    # Gather document contexts based on the retrieved indices\n",
    "    contexts = []\n",
    "    for idx in indices[0]:\n",
    "        if idx < len(metadata):  # Check to avoid index out of range\n",
    "            contexts.append(f\"{metadata[idx]['doc_name']} (Link: {metadata[idx]['doc_link']})\")\n",
    "\n",
    "    return contexts, distances[0]  # Return contexts and distances\n",
    "\n",
    "# Example usage\n",
    "query = \"Who are the executive officers in 3m comapany in 2015 ?\"\n",
    "top_docs, top_distances = retrieve_documents(query, index, metadata)\n",
    "\n",
    "# Prepare the context for the response\n",
    "context = \"\\n\".join(top_docs)\n",
    "response = generate_response(context, query)\n",
    "\n",
    "print(\"Response from Mistral AI:\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from Mistral AI:\n",
      "To provide you with the key financials of 3M for the year 2015, I would need to access the content of the 3M_2015_10K document. However, as I don't have direct access to external links or files, you can find the key financial information in the \"Financial Statements and Supplementary Data\" section of the 3M_2015_10K document available at the provided link.\n",
      "\n",
      "Generally, the key financials you would look for include:\n",
      "\n",
      "1. **Revenue**: Total sales or net revenues.\n",
      "2. **Net Income**: Profit after all expenses and taxes.\n",
      "3. **Earnings per Share (EPS)**: Net income divided by the number of outstanding shares.\n",
      "4. **Total Assets**: Overall value of what the company owns.\n",
      "5. **Total Liabilities**: Overall value of what the company owes.\n",
      "6. **Shareholders' Equity**: The difference between total assets and total liabilities.\n",
      "7. **Cash and Cash Equivalents**: Liquid assets that can be readily converted to cash.\n",
      "8. **Debt**: Long-term and short-term liabilities.\n",
      "\n",
      "To get the specific numbers for 3M in 2015, you can refer to the document linked as 3M_2\n",
      "Relevant Documents from actual PDFs:\n",
      "['3M_2015_10K', '3M_2016_10K']\n",
      "Precision@K: 0.00\n",
      "ROUGE scores: {'rouge-1': {'r': 0.46153846153846156, 'p': 0.05309734513274336, 'f': 0.09523809338750318}, 'rouge-2': {'r': 0.08333333333333333, 'p': 0.0064516129032258064, 'f': 0.011976046570332539}, 'rouge-l': {'r': 0.46153846153846156, 'p': 0.05309734513274336, 'f': 0.09523809338750318}}\n",
      "BLEU score: 0.00\n",
      "Factual Accuracy: Valid\n",
      "Response Latency: 5.12 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.metrics import precision_score\n",
    "from rouge import Rouge\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "# Set your Mistral API URL and API key\n",
    "mistral_api_url = \"https://api.mistral.ai/v1/chat/completions\"\n",
    "mistral_api_key = \"KoxLAEgGVZeEMPv3AJ3KSA4aJV6ZxPmo\"\n",
    "\n",
    "def generate_response(context, query):\n",
    "    \"\"\"Generate a response using Mistral AI.\"\"\"\n",
    "    prompt = f\"Based on the following content: {context}\\nAnswer the query: {query}\"\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {mistral_api_key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"mistral-small-latest\",  # Replace with the actual model name\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"max_tokens\": 300\n",
    "    }\n",
    "\n",
    "    response = requests.post(mistral_api_url, headers=headers, json=payload)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json()['choices'][0]['message']['content'].strip()\n",
    "    else:\n",
    "        raise Exception(f\"Error {response.status_code}: {response.text}\")\n",
    "\n",
    "def retrieve_documents(query, index, metadata, k=3):\n",
    "    \"\"\"Retrieve the top K most similar documents for a given query.\"\"\"\n",
    "    query_embedding = generate_embeddings(query).cpu().numpy()  # Ensure the embedding is on CPU\n",
    "    distances, indices = index.search(np.array([query_embedding]), k)\n",
    "\n",
    "    # Gather document contexts based on the retrieved indices\n",
    "    contexts = []\n",
    "    for idx in indices[0]:\n",
    "        if idx < len(metadata):  # Check to avoid index out of range\n",
    "            contexts.append(f\"{metadata[idx]['doc_name']} (Link: {metadata[idx]['doc_link']})\")\n",
    "\n",
    "    return contexts, distances[0]  # Return contexts and distances\n",
    "\n",
    "def evaluate_precision_at_k(retrieved_docs, relevant_docs, k=3):\n",
    "    \"\"\"Calculate Precision@K.\"\"\"\n",
    "    retrieved_set = set(retrieved_docs[:k])\n",
    "    relevant_set = set(relevant_docs)\n",
    "    true_positives = len(retrieved_set.intersection(relevant_set))\n",
    "\n",
    "    precision = true_positives / k\n",
    "    return precision\n",
    "\n",
    "def evaluate_rouge(reference, generated):\n",
    "    \"\"\"Evaluate ROUGE score.\"\"\"\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(generated, reference, avg=True)\n",
    "    return scores\n",
    "\n",
    "def evaluate_bleu(reference, generated):\n",
    "    \"\"\"Evaluate BLEU score.\"\"\"\n",
    "    reference = reference.split()  # Tokenize the reference\n",
    "    generated = generated.split()  # Tokenize the generated response\n",
    "    score = sentence_bleu([reference], generated)\n",
    "    return score\n",
    "\n",
    "def evaluate_factual_accuracy(response, ground_truth):\n",
    "    \"\"\"Check if the response contains valid information.\"\"\"\n",
    "    # This is a simplistic check; you can implement a more sophisticated one.\n",
    "    return any(term in response.lower() for term in ground_truth)\n",
    "\n",
    "# Example usage\n",
    "query = \"What are the key financials of 3M in 2015?\"\n",
    "top_docs, top_distances = retrieve_documents(query, index, metadata)\n",
    "\n",
    "# Prepare the context for the response\n",
    "context = \"\\n\".join(top_docs)\n",
    "\n",
    "# Measure latency and generate response\n",
    "start_time = time.time()\n",
    "response = generate_response(context, query)\n",
    "latency = time.time() - start_time\n",
    "\n",
    "print(\"Response from Mistral AI:\")\n",
    "print(response)\n",
    "\n",
    "# Define the ground truth and relevant documents for evaluation\n",
    "ground_truth = \"3M's key financials for 2015 include revenue, net income, and earnings per share.\"  # Example ground truth\n",
    "def extract_pdf_names(pdf_files):\n",
    "    return [os.path.splitext(os.path.basename(pdf))[0] for pdf in pdf_files]\n",
    "\n",
    "# Extract actual document names from the PDF file list\n",
    "relevant_docs = extract_pdf_names(pdf_files)\n",
    "\n",
    "print(\"Relevant Documents from actual PDFs:\")\n",
    "print(relevant_docs)\n",
    "# Evaluate Precision@K\n",
    "precision_at_k = evaluate_precision_at_k(top_docs, relevant_docs)\n",
    "print(f\"Precision@K: {precision_at_k:.2f}\")\n",
    "\n",
    "# Evaluate ROUGE\n",
    "rouge_scores = evaluate_rouge(ground_truth, response)\n",
    "print(f\"ROUGE scores: {rouge_scores}\")\n",
    "\n",
    "# Evaluate BLEU\n",
    "bleu_score = evaluate_bleu(ground_truth, response)\n",
    "print(f\"BLEU score: {bleu_score:.2f}\")\n",
    "\n",
    "# Evaluate Factual Accuracy\n",
    "factual_accuracy = evaluate_factual_accuracy(response, ground_truth)\n",
    "print(f\"Factual Accuracy: {'Valid' if factual_accuracy else 'Invalid'}\")\n",
    "\n",
    "# Print latency\n",
    "print(f\"Response Latency: {latency:.2f} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
